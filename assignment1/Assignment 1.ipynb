{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 224N: Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Softmax (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Implement softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running basic tests...\n",
      "[ 0.26894142  0.73105858]\n",
      "[[ 0.26894142  0.73105858]\n",
      " [ 0.26894142  0.73105858]]\n",
      "[[ 0.73105858  0.26894142]]\n",
      "You should be able to verify these results by hand!\n",
      "\n",
      "Running your tests...\n"
     ]
    }
   ],
   "source": [
    "%run q1_softmax.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Neural Network Basics (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Implement sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running basic tests...\n",
      "[[ 0.73105858  0.88079708]\n",
      " [ 0.26894142  0.11920292]]\n",
      "[[ 0.19661193  0.10499359]\n",
      " [ 0.19661193  0.10499359]]\n",
      "You should verify these results by hand!\n",
      "\n",
      "Running your tests...\n"
     ]
    }
   ],
   "source": [
    "%run q2_sigmoid.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Gradient check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sanity checks...\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "\n",
      "Running your sanity checks...\n"
     ]
    }
   ],
   "source": [
    "%run q2_gradcheck.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g). Implement the forward and backward passes for a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sanity check...\n",
      "Gradient check failed.\n",
      "First gradient error found at index (0,)\n",
      "Your gradient: -0.253772 \t Numerical gradient: 0.253772\n",
      "Running your sanity checks...\n"
     ]
    }
   ],
   "source": [
    "%run q2_neural.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. word2vec (40 points + 2 bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e). Implement the word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing normalizeRows...\n",
      "[[ 0.6         0.8       ]\n",
      " [ 0.4472136   0.89442719]]\n",
      "\n",
      "==== Gradient check for skip-gram ====\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "\n",
      "==== Gradient check for CBOW      ====\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "\n",
      "=== Results ===\n",
      "(11.166108785061258, array([[ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [-1.26947336, -1.36873024,  2.45159048],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[-0.4104582 ,  0.18835042,  1.4327257 ],\n",
      "       [ 0.38202654, -0.17530374, -1.33348351],\n",
      "       [ 0.07009331, -0.03216431, -0.24466434],\n",
      "       [ 0.09472137, -0.0434656 , -0.33062989],\n",
      "       [-0.13638302,  0.06258323,  0.47605203]]))\n",
      "(14.093692923613229, array([[ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [-3.86801854, -1.1271281 , -1.5266772 ],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[-0.11265051,  0.05169289,  0.39321248],\n",
      "       [-0.2271644 ,  0.10424085,  0.79292915],\n",
      "       [-0.79674433,  0.3656088 ,  2.78107754],\n",
      "       [-0.31602458,  0.14501687,  1.10310024],\n",
      "       [-0.80619947,  0.36994756,  2.81408119]]))\n",
      "(0.79899322297825415, array([[ 0.23330499, -0.51642938, -0.82812935],\n",
      "       [ 0.1166525 , -0.25821469, -0.41406467],\n",
      "       [ 0.1166525 , -0.25821469, -0.41406467],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[ 0.80954507,  0.21962212, -0.54095905],\n",
      "       [-0.03556579, -0.00964867,  0.02376598],\n",
      "       [-0.13016059, -0.03531137,  0.08697669],\n",
      "       [-0.16507985, -0.04478464,  0.11031065],\n",
      "       [-0.47873884, -0.12987744,  0.31990573]]))\n",
      "(7.8955675022677445, array([[-2.98871455, -3.38438375, -2.62674654],\n",
      "       [-1.49435728, -1.69219188, -1.31337327],\n",
      "       [-1.49435728, -1.69219188, -1.31337327],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[ 0.21992734,  0.05966426, -0.14696116],\n",
      "       [-1.37824661, -0.37390561,  0.9209802 ],\n",
      "       [-0.77701766, -0.21079773,  0.51922339],\n",
      "       [-2.58953666, -0.70251744,  1.73039568],\n",
      "       [-2.36748004, -0.64227552,  1.58201168]]))\n"
     ]
    }
   ],
   "source": [
    "%run q3_word2vec.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (f). SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sanity checks...\n",
      "iter 100: 0.004578\n",
      "iter 200: 0.004353\n",
      "iter 300: 0.004136\n",
      "iter 400: 0.003929\n",
      "iter 500: 0.003733\n",
      "iter 600: 0.003546\n",
      "iter 700: 0.003369\n",
      "iter 800: 0.003200\n",
      "iter 900: 0.003040\n",
      "iter 1000: 0.002888\n",
      "test 1 result: 8.414836786079764e-10\n",
      "iter 100: 0.000000\n",
      "iter 200: 0.000000\n",
      "iter 300: 0.000000\n",
      "iter 400: 0.000000\n",
      "iter 500: 0.000000\n",
      "iter 600: 0.000000\n",
      "iter 700: 0.000000\n",
      "iter 800: 0.000000\n",
      "iter 900: 0.000000\n",
      "iter 1000: 0.000000\n",
      "test 2 result: 0.0\n",
      "iter 100: 0.041205\n",
      "iter 200: 0.039181\n",
      "iter 300: 0.037222\n",
      "iter 400: 0.035361\n",
      "iter 500: 0.033593\n",
      "iter 600: 0.031913\n",
      "iter 700: 0.030318\n",
      "iter 800: 0.028802\n",
      "iter 900: 0.027362\n",
      "iter 1000: 0.025994\n",
      "test 3 result: -2.524451035823933e-09\n",
      "\n",
      "Running your sanity checks...\n"
     ]
    }
   ],
   "source": [
    "%run q3_sgd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g). Use the Stanford Sentiment Treebank (SST) dataset to train word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:1357: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 100: 19.824039\n",
      "iter 200: 19.885036\n",
      "iter 300: 20.049740\n",
      "iter 400: 20.168080\n",
      "iter 500: 20.188994\n",
      "iter 600: 20.437639\n",
      "iter 700: 20.399295\n",
      "iter 800: 20.561096\n",
      "iter 900: 20.493754\n",
      "iter 1000: 20.536539\n",
      "iter 1100: 20.554214\n",
      "iter 1200: 20.578520\n",
      "iter 1300: 20.563415\n",
      "iter 1400: 20.525984\n",
      "iter 1500: 20.452432\n",
      "iter 1600: 20.572657\n",
      "iter 1700: 20.519374\n",
      "iter 1800: 20.536106\n",
      "iter 1900: 20.545065\n",
      "iter 2000: 20.682110\n",
      "iter 2100: 20.776750\n",
      "iter 2200: 20.767022\n",
      "iter 2300: 20.842519\n",
      "iter 2400: 20.997134\n",
      "iter 2500: 21.175011\n",
      "iter 2600: 21.176830\n",
      "iter 2700: 21.216225\n",
      "iter 2800: 21.207287\n",
      "iter 2900: 21.287716\n",
      "iter 3000: 21.231135\n",
      "iter 3100: 21.076748\n",
      "iter 3200: 21.036459\n",
      "iter 3300: 20.883766\n",
      "iter 3400: 20.722535\n",
      "iter 3500: 20.819453\n",
      "iter 3600: 20.688059\n",
      "iter 3700: 20.614748\n",
      "iter 3800: 20.641461\n",
      "iter 3900: 20.608486\n",
      "iter 4000: 20.575084\n",
      "iter 4100: 20.362752\n",
      "iter 4200: 20.309977\n",
      "iter 4300: 20.205327\n",
      "iter 4400: 20.085116\n",
      "iter 4500: 19.967595\n",
      "iter 4600: 19.860409\n",
      "iter 4700: 19.798612\n",
      "iter 4800: 19.687301\n",
      "iter 4900: 19.570389\n",
      "iter 5000: 19.525727\n",
      "iter 5100: 19.333635\n",
      "iter 5200: 19.193091\n",
      "iter 5300: 19.064655\n",
      "iter 5400: 18.949365\n",
      "iter 5500: 18.960745\n",
      "iter 5600: 18.820863\n",
      "iter 5700: 18.733291\n",
      "iter 5800: 18.654855\n",
      "iter 5900: 18.433661\n",
      "iter 6000: 18.261690\n",
      "iter 6100: 18.138753\n",
      "iter 6200: 18.166158\n",
      "iter 6300: 18.049837\n",
      "iter 6400: 17.872774\n",
      "iter 6500: 17.743980\n",
      "iter 6600: 17.571580\n",
      "iter 6700: 17.418120\n",
      "iter 6800: 17.234311\n",
      "iter 6900: 17.103666\n",
      "iter 7000: 16.888436\n",
      "iter 7100: 16.753276\n",
      "iter 7200: 16.633309\n",
      "iter 7300: 16.598963\n",
      "iter 7400: 16.407169\n",
      "iter 7500: 16.265440\n",
      "iter 7600: 16.038123\n",
      "iter 7700: 16.017528\n",
      "iter 7800: 15.923757\n",
      "iter 7900: 15.813846\n",
      "iter 8000: 15.816978\n",
      "iter 8100: 15.638521\n",
      "iter 8200: 15.545030\n",
      "iter 8300: 15.492820\n",
      "iter 8400: 15.438031\n",
      "iter 8500: 15.376104\n",
      "iter 8600: 15.263065\n",
      "iter 8700: 15.169885\n",
      "iter 8800: 14.960506\n",
      "iter 8900: 14.877582\n",
      "iter 9000: 14.796511\n",
      "iter 9100: 14.696766\n",
      "iter 9200: 14.562331\n",
      "iter 9300: 14.402744\n",
      "iter 9400: 14.238913\n",
      "iter 9500: 14.187855\n",
      "iter 9600: 14.123986\n",
      "iter 9700: 14.099877\n",
      "iter 9800: 14.090614\n",
      "iter 9900: 14.028338\n",
      "iter 10000: 13.946136\n",
      "iter 10100: 13.839535\n",
      "iter 10200: 13.736119\n",
      "iter 10300: 13.826174\n",
      "iter 10400: 13.676668\n",
      "iter 10500: 13.675217\n",
      "iter 10600: 13.582738\n",
      "iter 10700: 13.658614\n",
      "iter 10800: 13.594066\n",
      "iter 10900: 13.472602\n",
      "iter 11000: 13.368513\n",
      "iter 11100: 13.371563\n",
      "iter 11200: 13.302402\n",
      "iter 11300: 13.299147\n",
      "iter 11400: 13.318848\n",
      "iter 11500: 13.190384\n",
      "iter 11600: 13.165637\n",
      "iter 11700: 13.090212\n",
      "iter 11800: 13.008920\n",
      "iter 11900: 13.033409\n",
      "iter 12000: 13.027228\n",
      "iter 12100: 12.930036\n",
      "iter 12200: 12.913873\n",
      "iter 12300: 12.833465\n",
      "iter 12400: 12.805478\n",
      "iter 12500: 12.727694\n",
      "iter 12600: 12.668530\n",
      "iter 12700: 12.545081\n",
      "iter 12800: 12.538326\n",
      "iter 12900: 12.493928\n",
      "iter 13000: 12.408140\n",
      "iter 13100: 12.337020\n",
      "iter 13200: 12.257376\n",
      "iter 13300: 12.248533\n",
      "iter 13400: 12.175160\n",
      "iter 13500: 12.131960\n",
      "iter 13600: 12.068603\n",
      "iter 13700: 12.013304\n",
      "iter 13800: 11.915335\n",
      "iter 13900: 11.936055\n",
      "iter 14000: 11.861430\n",
      "iter 14100: 11.845763\n",
      "iter 14200: 11.833217\n",
      "iter 14300: 11.708718\n",
      "iter 14400: 11.695166\n",
      "iter 14500: 11.640625\n",
      "iter 14600: 11.573429\n",
      "iter 14700: 11.547820\n",
      "iter 14800: 11.487369\n",
      "iter 14900: 11.514052\n",
      "iter 15000: 11.446610\n",
      "iter 15100: 11.351004\n",
      "iter 15200: 11.423952\n",
      "iter 15300: 11.427936\n",
      "iter 15400: 11.369033\n",
      "iter 15500: 11.410569\n",
      "iter 15600: 11.306575\n",
      "iter 15700: 11.284175\n",
      "iter 15800: 11.204599\n",
      "iter 15900: 11.151113\n",
      "iter 16000: 11.144022\n",
      "iter 16100: 11.096273\n",
      "iter 16200: 11.098590\n",
      "iter 16300: 11.021333\n",
      "iter 16400: 11.124306\n",
      "iter 16500: 11.074790\n",
      "iter 16600: 11.065632\n",
      "iter 16700: 11.057241\n",
      "iter 16800: 11.060486\n",
      "iter 16900: 10.968989\n",
      "iter 17000: 10.834137\n",
      "iter 17100: 10.849230\n",
      "iter 17200: 10.800077\n",
      "iter 17300: 10.837802\n",
      "iter 17400: 10.796570\n",
      "iter 17500: 10.772722\n",
      "iter 17600: 10.819055\n",
      "iter 17700: 10.847020\n",
      "iter 17800: 10.847068\n",
      "iter 17900: 10.785078\n",
      "iter 18000: 10.800104\n",
      "iter 18100: 10.739881\n",
      "iter 18200: 10.729772\n",
      "iter 18300: 10.632947\n",
      "iter 18400: 10.545841\n",
      "iter 18500: 10.500250\n",
      "iter 18600: 10.498625\n",
      "iter 18700: 10.389733\n",
      "iter 18800: 10.402867\n",
      "iter 18900: 10.321647\n",
      "iter 19000: 10.335057\n",
      "iter 19100: 10.322154\n",
      "iter 19200: 10.314441\n",
      "iter 19300: 10.313528\n",
      "iter 19400: 10.301681\n",
      "iter 19500: 10.283361\n",
      "iter 19600: 10.309080\n",
      "iter 19700: 10.278458\n",
      "iter 19800: 10.281873\n",
      "iter 19900: 10.277474\n",
      "iter 20000: 10.247567\n",
      "iter 20100: 10.244736\n",
      "iter 20200: 10.297014\n",
      "iter 20300: 10.310027\n",
      "iter 20400: 10.285390\n",
      "iter 20500: 10.271749\n",
      "iter 20600: 10.299147\n",
      "iter 20700: 10.301867\n",
      "iter 20800: 10.262997\n",
      "iter 20900: 10.162900\n",
      "iter 21000: 10.099895\n",
      "iter 21100: 10.102029\n",
      "iter 21200: 10.110211\n",
      "iter 21300: 10.185343\n",
      "iter 21400: 10.175604\n",
      "iter 21500: 10.102431\n",
      "iter 21600: 10.119033\n",
      "iter 21700: 10.081440\n",
      "iter 21800: 10.083437\n",
      "iter 21900: 10.131026\n",
      "iter 22000: 10.088182\n",
      "iter 22100: 10.058636\n",
      "iter 22200: 10.033191\n",
      "iter 22300: 10.045275\n",
      "iter 22400: 10.020977\n",
      "iter 22500: 10.097764\n",
      "iter 22600: 10.215133\n",
      "iter 22700: 10.227845\n",
      "iter 22800: 10.197628\n",
      "iter 22900: 10.237663\n",
      "iter 23000: 10.263338\n",
      "iter 23100: 10.291507\n",
      "iter 23200: 10.229308\n",
      "iter 23300: 10.210151\n",
      "iter 23400: 10.177065\n",
      "iter 23500: 10.164823\n",
      "iter 23600: 10.226700\n",
      "iter 23700: 10.170871\n",
      "iter 23800: 10.090427\n",
      "iter 23900: 10.145882\n",
      "iter 24000: 10.149304\n",
      "iter 24100: 10.216472\n",
      "iter 24200: 10.181206\n",
      "iter 24300: 10.172605\n",
      "iter 24400: 10.150431\n",
      "iter 24500: 10.117911\n",
      "iter 24600: 10.085351\n",
      "iter 24700: 10.072551\n",
      "iter 24800: 10.081037\n",
      "iter 24900: 10.033583\n",
      "iter 25000: 10.110142\n",
      "iter 25100: 10.130407\n",
      "iter 25200: 10.128325\n",
      "iter 25300: 10.144825\n",
      "iter 25400: 10.071745\n",
      "iter 25500: 10.056604\n",
      "iter 25600: 9.999437\n",
      "iter 25700: 10.014155\n",
      "iter 25800: 10.094063\n",
      "iter 25900: 10.085610\n",
      "iter 26000: 10.076930\n",
      "iter 26100: 10.047669\n",
      "iter 26200: 10.073634\n",
      "iter 26300: 10.053816\n",
      "iter 26400: 10.017442\n",
      "iter 26500: 10.018007\n",
      "iter 26600: 9.960825\n",
      "iter 26700: 10.018164\n",
      "iter 26800: 9.974567\n",
      "iter 26900: 10.026218\n",
      "iter 27000: 10.045995\n",
      "iter 27100: 10.041788\n",
      "iter 27200: 10.040363\n",
      "iter 27300: 10.010601\n",
      "iter 27400: 9.982874\n",
      "iter 27500: 9.961519\n",
      "iter 27600: 9.957203\n",
      "iter 27700: 9.960586\n",
      "iter 27800: 9.939444\n",
      "iter 27900: 9.983696\n",
      "iter 28000: 9.954447\n",
      "iter 28100: 9.978567\n",
      "iter 28200: 9.957449\n",
      "iter 28300: 9.948769\n",
      "iter 28400: 9.938915\n",
      "iter 28500: 9.975253\n",
      "iter 28600: 9.889403\n",
      "iter 28700: 9.918757\n",
      "iter 28800: 9.832231\n",
      "iter 28900: 9.802469\n",
      "iter 29000: 9.773261\n",
      "iter 29100: 9.810245\n",
      "iter 29200: 9.734603\n",
      "iter 29300: 9.762057\n",
      "iter 29400: 9.776185\n",
      "iter 29500: 9.788518\n",
      "iter 29600: 9.759733\n",
      "iter 29700: 9.737637\n",
      "iter 29800: 9.672855\n",
      "iter 29900: 9.694123\n",
      "iter 30000: 9.762889\n",
      "iter 30100: 9.759218\n",
      "iter 30200: 9.803428\n",
      "iter 30300: 9.855204\n",
      "iter 30400: 9.782410\n",
      "iter 30500: 9.790716\n",
      "iter 30600: 9.799996\n",
      "iter 30700: 9.815427\n",
      "iter 30800: 9.804867\n",
      "iter 30900: 9.826879\n",
      "iter 31000: 9.839455\n",
      "iter 31100: 9.841768\n",
      "iter 31200: 9.827142\n",
      "iter 31300: 9.808651\n",
      "iter 31400: 9.812901\n",
      "iter 31500: 9.811398\n",
      "iter 31600: 9.880335\n",
      "iter 31700: 9.842280\n",
      "iter 31800: 9.813051\n",
      "iter 31900: 9.864720\n",
      "iter 32000: 9.877827\n",
      "iter 32100: 9.822486\n",
      "iter 32200: 9.834951\n",
      "iter 32300: 9.742492\n",
      "iter 32400: 9.662566\n",
      "iter 32500: 9.618084\n",
      "iter 32600: 9.607787\n",
      "iter 32700: 9.630981\n",
      "iter 32800: 9.630232\n",
      "iter 32900: 9.640462\n",
      "iter 33000: 9.617710\n",
      "iter 33100: 9.584874\n",
      "iter 33200: 9.615466\n",
      "iter 33300: 9.616651\n",
      "iter 33400: 9.607896\n",
      "iter 33500: 9.617241\n",
      "iter 33600: 9.644067\n",
      "iter 33700: 9.629553\n",
      "iter 33800: 9.601024\n",
      "iter 33900: 9.642204\n",
      "iter 34000: 9.670860\n",
      "iter 34100: 9.683814\n",
      "iter 34200: 9.733686\n",
      "iter 34300: 9.732561\n",
      "iter 34400: 9.703381\n",
      "iter 34500: 9.713676\n",
      "iter 34600: 9.768275\n",
      "iter 34700: 9.706456\n",
      "iter 34800: 9.703096\n",
      "iter 34900: 9.640430\n",
      "iter 35000: 9.753083\n",
      "iter 35100: 9.803072\n",
      "iter 35200: 9.779322\n",
      "iter 35300: 9.794212\n",
      "iter 35400: 9.819046\n",
      "iter 35500: 9.843211\n",
      "iter 35600: 9.854026\n",
      "iter 35700: 9.851577\n",
      "iter 35800: 9.789891\n",
      "iter 35900: 9.774153\n",
      "iter 36000: 9.753306\n",
      "iter 36100: 9.726266\n",
      "iter 36200: 9.722454\n",
      "iter 36300: 9.729469\n",
      "iter 36400: 9.646707\n",
      "iter 36500: 9.707360\n",
      "iter 36600: 9.650556\n",
      "iter 36700: 9.680000\n",
      "iter 36800: 9.604968\n",
      "iter 36900: 9.612186\n",
      "iter 37000: 9.596270\n",
      "iter 37100: 9.487940\n",
      "iter 37200: 9.463273\n",
      "iter 37300: 9.501518\n",
      "iter 37400: 9.552882\n",
      "iter 37500: 9.581351\n",
      "iter 37600: 9.560424\n",
      "iter 37700: 9.598664\n",
      "iter 37800: 9.526556\n",
      "iter 37900: 9.501445\n",
      "iter 38000: 9.545910\n",
      "iter 38100: 9.499444\n",
      "iter 38200: 9.464316\n",
      "iter 38300: 9.471638\n",
      "iter 38400: 9.582512\n",
      "iter 38500: 9.634933\n",
      "iter 38600: 9.620018\n",
      "iter 38700: 9.659647\n",
      "iter 38800: 9.619711\n",
      "iter 38900: 9.594142\n",
      "iter 39000: 9.530056\n",
      "iter 39100: 9.493568\n",
      "iter 39200: 9.483587\n",
      "iter 39300: 9.473853\n",
      "iter 39400: 9.483695\n",
      "iter 39500: 9.414804\n",
      "iter 39600: 9.415709\n",
      "iter 39700: 9.418263\n",
      "iter 39800: 9.441739\n",
      "iter 39900: 9.456463\n",
      "iter 40000: 9.403927\n",
      "sanity check: cost at convergence should be around or below 10\n",
      "training took 16100 seconds\n"
     ]
    }
   ],
   "source": [
    "%run q3_run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis (20 points)\n",
    "Note: This part is done with Python 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\python2\\lib\\site-packages\\matplotlib\\__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for reg=0.000000\n",
      "Train accuracy (%): 39.922753\n",
      "Dev accuracy (%): 36.330609\n",
      "Test accuracy (%): 36.968326\n",
      "Training for reg=0.000000\n",
      "Train accuracy (%): 39.934457\n",
      "Dev accuracy (%): 36.330609\n",
      "Test accuracy (%): 36.968326\n",
      "Training for reg=0.000000\n",
      "Train accuracy (%): 39.911049\n",
      "Dev accuracy (%): 36.603088\n",
      "Test accuracy (%): 37.058824\n",
      "Training for reg=0.000000\n",
      "Train accuracy (%): 39.957865\n",
      "Dev accuracy (%): 36.512262\n",
      "Test accuracy (%): 36.968326\n",
      "Training for reg=0.000000\n",
      "Train accuracy (%): 39.922753\n",
      "Dev accuracy (%): 36.330609\n",
      "Test accuracy (%): 36.968326\n",
      "Training for reg=0.000006\n",
      "Train accuracy (%): 39.899345\n",
      "Dev accuracy (%): 36.603088\n",
      "Test accuracy (%): 37.058824\n",
      "Training for reg=0.000098\n",
      "Train accuracy (%): 39.922753\n",
      "Dev accuracy (%): 36.603088\n",
      "Test accuracy (%): 37.058824\n",
      "Training for reg=0.004041\n",
      "Train accuracy (%): 39.946161\n",
      "Dev accuracy (%): 36.330609\n",
      "Test accuracy (%): 37.058824\n",
      "Training for reg=0.068435\n",
      "Train accuracy (%): 39.875936\n",
      "Dev accuracy (%): 36.330609\n",
      "Test accuracy (%): 37.239819\n",
      "Training for reg=0.096141\n",
      "Train accuracy (%): 39.840824\n",
      "Dev accuracy (%): 36.239782\n",
      "Test accuracy (%): 37.194570\n",
      "Training for reg=0.200214\n",
      "Train accuracy (%): 39.758895\n",
      "Dev accuracy (%): 36.421435\n",
      "Test accuracy (%): 37.330317\n",
      "Training for reg=0.782287\n",
      "Train accuracy (%): 39.536517\n",
      "Dev accuracy (%): 36.603088\n",
      "Test accuracy (%): 37.285068\n",
      "Training for reg=5.540409\n",
      "Train accuracy (%): 39.021536\n",
      "Dev accuracy (%): 36.421435\n",
      "Test accuracy (%): 37.420814\n",
      "Training for reg=8.934721\n",
      "Train accuracy (%): 38.728933\n",
      "Dev accuracy (%): 36.693915\n",
      "Test accuracy (%): 37.828054\n",
      "Training for reg=99.829234\n",
      "Train accuracy (%): 36.341292\n",
      "Dev accuracy (%): 35.059037\n",
      "Test accuracy (%): 35.701357\n",
      "Training for reg=312.171776\n",
      "Train accuracy (%): 34.421816\n",
      "Dev accuracy (%): 33.151680\n",
      "Test accuracy (%): 33.936652\n",
      "Training for reg=561.928395\n",
      "Train accuracy (%): 33.333333\n",
      "Dev accuracy (%): 32.152589\n",
      "Test accuracy (%): 33.076923\n",
      "Training for reg=2900.825149\n",
      "Train accuracy (%): 29.084738\n",
      "Dev accuracy (%): 28.156222\n",
      "Test accuracy (%): 26.289593\n",
      "Training for reg=3497.184982\n",
      "Train accuracy (%): 28.546348\n",
      "Dev accuracy (%): 27.157130\n",
      "Test accuracy (%): 25.384615\n",
      "Training for reg=21411.397523\n",
      "Train accuracy (%): 27.247191\n",
      "Dev accuracy (%): 25.522252\n",
      "Test accuracy (%): 23.031674\n",
      "\n",
      "=== Recap ===\n",
      "Reg\t\tTrain\tDev\tTest\n",
      "5.86E-10\t39.923\t36.331\t36.968\n",
      "1.08E-09\t39.934\t36.331\t36.968\n",
      "3.83E-08\t39.911\t36.603\t37.059\n",
      "1.97E-07\t39.958\t36.512\t36.968\n",
      "4.31E-07\t39.923\t36.331\t36.968\n",
      "5.84E-06\t39.899\t36.603\t37.059\n",
      "9.80E-05\t39.923\t36.603\t37.059\n",
      "4.04E-03\t39.946\t36.331\t37.059\n",
      "6.84E-02\t39.876\t36.331\t37.240\n",
      "9.61E-02\t39.841\t36.240\t37.195\n",
      "2.00E-01\t39.759\t36.421\t37.330\n",
      "7.82E-01\t39.537\t36.603\t37.285\n",
      "5.54E+00\t39.022\t36.421\t37.421\n",
      "8.93E+00\t38.729\t36.694\t37.828\n",
      "9.98E+01\t36.341\t35.059\t35.701\n",
      "3.12E+02\t34.422\t33.152\t33.937\n",
      "5.62E+02\t33.333\t32.153\t33.077\n",
      "2.90E+03\t29.085\t28.156\t26.290\n",
      "3.50E+03\t28.546\t27.157\t25.385\n",
      "2.14E+04\t27.247\t25.522\t23.032\n",
      "\n",
      "Best regularization value: 8.93E+00\n",
      "Test accuracy (%): 37.828054\n"
     ]
    }
   ],
   "source": [
    "%run q4_sentiment.py --pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\python2\\lib\\site-packages\\matplotlib\\__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\Dropbox\\study (ms)\\self study\\cs224\\assignment1\\q4_sentiment.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetArguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Dropbox\\study (ms)\\self study\\cs224\\assignment1\\q4_sentiment.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myourvectors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordVectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_saved_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m         wordVectors = np.concatenate(\n\u001b[0;32m    158\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mwordVectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnWords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordVectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnWords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Dropbox\\study (ms)\\self study\\cs224\\assignment1\\q3_sgd.py\u001b[0m in \u001b[0;36mload_saved_params\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mst\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved_params_%d.npy\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unsupported pickle protocol: 3"
     ]
    }
   ],
   "source": [
    "# Note: Error due to previouly dumping the parameters with pickle protocol 3 in Python 3. This part is incomplete.\n",
    "%run q4_sentiment.py --yourvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
